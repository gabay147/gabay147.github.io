[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Felix Gabay",
    "section": "",
    "text": "Hi! I’m Felix Gabay, and I’m a behavioral neuroscience undergrad at the University of Kansas also pursuing a data science certificate. A research assistant at the Affective Communication & Computing Lab (AffCom), my research interests include interpersonal relationships and emotional regulation in persons with ADHD, ASD, and other forms of neurodivergence. My work includes data processing, data analytics, and statistical analysis."
  },
  {
    "objectID": "posts/Data2-U1-Grp_Prj/index.html",
    "href": "posts/Data2-U1-Grp_Prj/index.html",
    "title": "Unit 1 Project - Alcohol Use Disorder in Adolescents",
    "section": "",
    "text": "This group project was for PSYC 399 - Data 2 in the spring semester of 2025. With my team, we were tasked with finding our own dataset (or combining datasets into one), wrangling the data, and analyzing the data. As this is the first group project of the semester, it was mostly focused on creating graphics with GGPlot to find correlations.\nI also took a leadership position and worked on coordinating the team, delegating efforts, and communicating with the instructional team for feedback and assistance. As a result, we developed the following report, receiving a nearly-perfect grade."
  },
  {
    "objectID": "posts/Data2-U1-Grp_Prj/index.html#overview",
    "href": "posts/Data2-U1-Grp_Prj/index.html#overview",
    "title": "Unit 1 Project - Alcohol Use Disorder in Adolescents",
    "section": "Overview",
    "text": "Overview\nFor our project, we decided to look at a topic based in social sciences due to a connection to our majors and interest areas. We focused on drug abuse and found a data set concerning the substance abuse disorders in the 50 states and District of Columbia. We decided to look at alcohol use disorder primarily, with a secondary analysis comparing alcohol and marijuana use."
  },
  {
    "objectID": "posts/Data2-U1-Grp_Prj/index.html#data-wrangling",
    "href": "posts/Data2-U1-Grp_Prj/index.html#data-wrangling",
    "title": "Unit 1 Project - Alcohol Use Disorder in Adolescents",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n\nCode\n# Load resources\nlibrary(tidyverse)\n\nd &lt;- read.csv(\"data/drugs.csv\")\n\n\nWe found a data source through corgis.edu, a site Felix had worked with in the past. This source had more than enough observations, so we did not have to combine multiple sources and only had to download it as a CSV file and load it into RStudio.\nFrom there, we filtered the dataset to keep only years 2018, 2013, and 2008. We also dropped most of the columns, keeping only “State,” “Year,” “Rates.Alcohol.Use.Disorder.Past.Year.12.17”, “Rates.Alcohol.Use.Disorder.Past.Year.18.25”, and “Rates.Marijuana.Used.Past.Year.12.17. The last three columns were renamed to”Rates_12_17”, “Rates_18_25”, and “Mari_12_17” respectively.\n“State” is character data that includes all 50 states plus the District of Columbia.\n“Year” is integer data that spanned from 2002 to 2018, though we filtered down to only leave 2018, 2013, and 2008.\n“Rates_12_17”, “Rates_18_25”, and “Mari_12_17” are all integer data that was calculated in the original dataset from a Totals column and a Population column. We decided to remove both of these columns. The 12_17 and 18_25 indicate age range.\n\n\nCode\n# Create vectors by isolating data that fits our criteria for Population A (12-17)\nPopA &lt;- d |&gt; \n  filter(Year == \"2018\" | Year == \"2013\" | Year == \"2008\") |&gt;\n  select(c(\n    State, \n    Year, \n    Rates.Alcohol.Use.Disorder.Past.Year.12.17, \n    Rates.Alcohol.Use.Disorder.Past.Year.18.25, \n    Rates.Marijuana.Used.Past.Year.12.17\n    )\n  ) # Select the columns of interest\n\n# Felix 3-5-25\n\n# AUD (Alcohol Use Disorder) [for ages 12-17]\n# Added Mari_12_17 - rates of marijuana use in past year for same age group\nAUD &lt;- tibble( # Create tibble AUD, set variables\n  State = PopA$State,\n  Year = PopA$Year,\n  Rates_12_17 = PopA$Rates.Alcohol.Use.Disorder.Past.Year.12.17,\n  Rates_18_25 = PopA$Rates.Alcohol.Use.Disorder.Past.Year.18.25,\n  Mari_12_17 = PopA$Rates.Marijuana.Used.Past.Year.12.17\n)\n\nAUD\n\n\n# A tibble: 153 × 5\n   State                 Year Rates_12_17 Rates_18_25 Mari_12_17\n   &lt;chr&gt;                &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alabama               2008        41.2        137.       101.\n 2 Alaska                2008        53.1        169.       159.\n 3 Arizona               2008        54.0        182.       143.\n 4 Arkansas              2008        49.0        156.       123.\n 5 California            2008        52.7        164.       151.\n 6 Colorado              2008        63.2        210.       185.\n 7 Connecticut           2008        59.2        199.       159.\n 8 Delaware              2008        48.6        190.       155.\n 9 District of Columbia  2008        30.4        170.       146.\n10 Florida               2008        43.3        146.       129.\n# ℹ 143 more rows\n\n\nCode\n# Felix 3-5-25"
  },
  {
    "objectID": "posts/Data2-U1-Grp_Prj/index.html#visualization",
    "href": "posts/Data2-U1-Grp_Prj/index.html#visualization",
    "title": "Unit 1 Project - Alcohol Use Disorder in Adolescents",
    "section": "Visualization",
    "text": "Visualization\n\nFig. A) Comparing alcohol use between all 50 states\nAlayna - My part in the Unit 1 Group Project’s visualizations was to create a histogram. The coding I used was imported using the read.csv () command and was made to include the years 2008, 2013, and 2018. The column titled “Rates.Alcohol.Use.Disorder.Past.Year.18.25” was changed to “Rates” for clarity. The x-axis symbolized the rates variable that acted for the percentage of 18-25 years olds with alcohol use disorder, while the y-axis represented the state variable that was reorganized based on the Rates. The fill aesthetic was based on the year variable, making the different years different shades of green (pale green, lime green, and forest green). The geom_histogram(stat = “identity”) command displayed the alcohol use disorder rates as bars. Position = “dodge” ensured that the bars for the years (2008, 2013, 2018) were placed next to each other for comparison. The width = 0.7 command was used to help with the bars’ visibility.\n\n\nCode\ndf &lt;- read.csv(\"data/drugs.csv\")\n\ndf_filtered &lt;- df %&gt;%\n  filter (Year %in% c(2008, 2013, 2018)) %&gt;%\n  select(State, Year, Rates = 'Rates.Alcohol.Use.Disorder.Past.Year.18.25')\n\nggplot(df_filtered, aes(\n  x = Rates, \n  y = reorder(State, Rates), \n  fill = factor (Year))) +\n  geom_histogram(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  labs(title = \"Alcohol Use Disorder Rates (Ages 18-25) by State\",\n       y = \"States\",\n       x = \"Rates (%)\",\n       fill = \"Year\",\n       caption = \"Data from corgis.edu\") +\n  scale_fill_manual(\n    values = c(\n      \"2008\" = \"palegreen\", \n      \"2013\" = \"limegreen\", \n      \"2018\" = \"forestgreen\")\n    ) +\n  theme_minimal (base_size = 8) +\n  theme(axis.text.x = element_text(\n    angle = 360, \n    hjust = 1, \n    vjust = 0.5, \n    size = 4.7)\n  )\n\n\n\n\n\n\n\n\n\n\n\nFig. B) Comparing national alcohol use rates over time\nEmry - I was tasked with creating a temporal visualization showcasing the three years we chose. To do this, I mapped Year to the x-axis and rates to the y-axis. I knew that I wanted to use a jitter plot since there were only three values along the x axis, though I did not know how to represent both age groups. I spoke with Dr. Girard and he introduced the pivot_longer command. I also added a geom_smooth line to show the trend of the datapoints for each age group. Beyond this, the rest of the code was added for aesthetic purposes, such as sizing and cleaning up the scale.\n\n\nCode\n#Create tibble, join rates columns into column Age_Group with new column rates\nAUD2 &lt;-\n  AUD |&gt; \n  pivot_longer(\n    Rates_12_17:Rates_18_25,\n    names_to = \"Age_Group\",\n    values_to = \"Rate\"\n  )\n\n#Create+format figure showing rate by year with both age groups colored coded\n\nggplot(AUD2, aes(x = Year, y = Rate, color = Age_Group)) + geom_jitter() + \n  scale_color_discrete(\n    labels = c(\"Rates_12_17\" = \"12-17\", \"Rates_18_25\" = \"18-25\")) + \n  labs(title = \"AUD rates in USA, District of Columbia by age over time\") +\n  scale_x_continuous(breaks = c(2008, 2013, 2018)) +\n  theme_bw(base_size = 10) +\n  geom_smooth(method = \"lm\") +\n  labs(color = \"Age Group\") +\n  labs(caption = \"Data from corgis.edu\")\n\n\n\n\n\n\n\n\n\nCode\n# Scale shows three years we are focusing on\n# Sizing changed so title is not cut off\n# Linear regression added to demonstrate trend\n# Emry 3.11.25\n\n\n\n\nFig. C) Comparing alcohol use between age groups and states: KS and MO\nSev - The process of deciding on my figure was a trial and error one. I first played around with the box plot but decided that it was not as clear. Then I transitioned into a violin plot, but it was still confusing to look at visually. Then I came to the final conclusion of using the density plot because it was really easy to see visually. One of the things that I struggled with was putting all of the data onto the density plot. The way I combatted this was making one of the data points “Ages 18-25” a dashed line so it was easier to distinguish between them. Asked Dr. Girard on how to make it look visually better and he used pivot_longer and helped us with the code.\n\n\nCode\n## Filters the dataset for Kansas and Missouri\nPopB &lt;- d |&gt; \n  filter(State == \"Kansas\" | State == \"Missouri\") |&gt; \n  select(\n    State, \n    Year, \n    Rates.Alcohol.Use.Disorder.Past.Year.12.17, \n    Rates.Alcohol.Use.Disorder.Past.Year.18.25) |&gt;\n  pivot_longer(\n    cols = c(\n      Rates.Alcohol.Use.Disorder.Past.Year.18.25, \n      Rates.Alcohol.Use.Disorder.Past.Year.12.17), \n    names_to = \"Age\", \n    values_to = \"Rate\",\n    names_prefix = \"Rates.Alcohol.Use.Disorder.Past.Year.\"\n  )\n\nggplot(PopB) +\n  # Plots ages 12-17\n  geom_density(aes(x = Rate, color = State, linetype = Age), linewidth = 2) +\n  labs(\n    x = \"Rates of Alcohol Use Ages 12-17 & Dashed Line = 18-25.\",\n    y = \"Density (Different rates of alcohol use disorder KS & MO)\",\n    fill = \"State\",\n    color = \"State\"\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Sev 3.12.25\n\n\n\n\nFig D) Comparing Alcohol Use and Marijuana Use\nFelix - For this graph I wanted to see if there was a correlation between alcohol use and marijuana use in the past year for the 12-17 age group. I tried a couple of different plots, but a simple scatterplot was the best approach to look at two continuous variables. I added a smooth so that it would show the mean trend line. To differentiate the years that we isolated (2008, 2013, 2018), I set both color and shape to be mapped to the year.\n\n\nCode\n# Creates a scatterplot comparing rates of alcohol use and marijuana use in the past year for ages 12-17\n\nggplot(AUD, \n  aes(\n    y = Rates_12_17, \n    x = Mari_12_17, \n    color = factor(Year), \n    shape = factor(Year)\n    )\n  ) + \n  geom_point() +\n  geom_smooth() +\n  labs(\n    title = \"Substance use in ages 12-17 in the USA\",\n    subtitle = \"2008 shows some correlation between alcohol use and marijuana use, others show little effect\",\n    caption = \"Data from CORGIS Dataset Project\",\n    \n    x = \"Rates of Marijuana Use in Past Year\",\n    y = \"Rates of Alcohol Use in Past Year\",\n    \n    color = \"Year\",\n    shape = \"Year\"\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Felix 3-12-25"
  },
  {
    "objectID": "posts/Data2-U1-Grp_Prj/index.html#conclusions",
    "href": "posts/Data2-U1-Grp_Prj/index.html#conclusions",
    "title": "Unit 1 Project - Alcohol Use Disorder in Adolescents",
    "section": "Conclusions",
    "text": "Conclusions\nBased on our graphs, we can see that alcohol use in the 12-17 age category across the country was on the decline during the 10-year period that we observed. We can also see that both Kansas and Missouri show similar trends in alcohol use between the 12-17 and 18-25 age groups. This trend is supported on the national level, where we see a higher density of high-rate alcohol use in the 18-25 age category than the 12-17, which makes sense due to national liquor laws. As for correlating alcohol use with another drug, like marijuana, we did not see a significant connection between the two.\nFor conclusions based on individual figures, see the following:\n\nFig. A - Alayna\nThe histogram shows that Montana had the largest alcohol use disorder rate in 2008 (245.91%), while Utah had the smallest alcohol use disorder rate in 2008 (124.2%). New Hampshire had the largest alcohol use disorder rate in 2013 (171.7%), while Louisiana had the smallest alcohol use disorder rate in 2013 (101.306%). New Hampshire had the highest alcohol use disorder rate in 2018 (143.95%), while Florida had the smallest alcohol use disorder rate in 2018 (71.22%).\n\n\nFig. B - Emry\nThe age range of 18-25 has higher overall rates of Alcohol Use Disorder rates. However, though both age groups see a downturn in rates across time, 18-25 sees a steeper negative regression slope.\n\n\nFig. C - Sev\nThis graph shows that for people ages 12-17, the consumption of alcohol was greater in Kansas for the majority of the time. For people ages 18-25, the consumption of alcohol was greater in Kansas as well with a big change at around 180 rates.\n\n\nFig. D - Felix\nThis graph shows that there are no major correlations between alcohol use and marijuana use for the 12-17 age group for the years that we selected. 2008 shows a greater slope, suggesting a correlation, but the points vary significantly, so this could be due to outlier influence. Overall, we can see that rates of alcohol use throughout the US decreased over 10 years, with marijuana use remaining relatively steady, with some states reporting greater use, and some with less."
  },
  {
    "objectID": "posts/Data-2-Retrospective/Data 2 Retrospective.html",
    "href": "posts/Data-2-Retrospective/Data 2 Retrospective.html",
    "title": "A Data 2 Retrospective",
    "section": "",
    "text": "I took Data 2 in the spring semester of 2025, the start of my senior year. Although I’m studying behavioral neuroscience, I’m no stranger to programming, code, and data. I started my higher education journey at Kansas State University (Go Wildcats!) in 2015, where I studied computer science for 3 semesters, then digital media technology for another 3. During this time, I developed the foundational coding skills that Data 2 would later build on.\n\n\nMy favorite aspect of Data 2 was the data visualization. I really enjoy making data (which is often overwhelmingly vast) accessible to people of all skill levels. My background in programming gave me a strong lead in building visualizations, which gave me ample space to explore making my graphics clean.\nAnother major aspect of this course was data manipulation. This topic is quite a bit more complex."
  },
  {
    "objectID": "posts/Data-2-Retrospective/Data 2 Retrospective.html#all-about-data-2",
    "href": "posts/Data-2-Retrospective/Data 2 Retrospective.html#all-about-data-2",
    "title": "A Data 2 Retrospective",
    "section": "",
    "text": "I took Data 2 in the spring semester of 2025, the start of my senior year. Although I’m studying behavioral neuroscience, I’m no stranger to programming, code, and data. I started my higher education journey at Kansas State University (Go Wildcats!) in 2015, where I studied computer science for 3 semesters, then digital media technology for another 3. During this time, I developed the foundational coding skills that Data 2 would later build on.\n\n\nMy favorite aspect of Data 2 was the data visualization. I really enjoy making data (which is often overwhelmingly vast) accessible to people of all skill levels. My background in programming gave me a strong lead in building visualizations, which gave me ample space to explore making my graphics clean.\nAnother major aspect of this course was data manipulation. This topic is quite a bit more complex."
  },
  {
    "objectID": "posts/Data-2-Retrospective/Data 2 Retrospective.html#every-lecture-activity-for-data-2",
    "href": "posts/Data-2-Retrospective/Data 2 Retrospective.html#every-lecture-activity-for-data-2",
    "title": "A Data 2 Retrospective",
    "section": "Every Lecture Activity for Data 2",
    "text": "Every Lecture Activity for Data 2\nAs the semester came to an end, I decided it would be beneficial to work through the entirety of the lecture activities for this course. It’s a good way to revisit the fundamentals and rehearse all of the skills that I’ve learned since January.\n\nLibraries and resources\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\n\n\n\nWeek 2\nQ 1\nThis one was just asking to correct the following commands that were throwing errors:\n\n\n[20 + .2] \\ 4.1\n\n\n6 x (2 + 1,300)\n\n\nThese are pretty obvious formatting errors. - Square brackets [ ] should instead be parentheses ( ) for grouping an operation. - The back-slash \\ should be the forward-slash / for division - An “x” was used instead of the asterisk for multiplication - A comma was added to 1300, disrupting the numeric value\nSolution:\n\n\nSimple arithmetic in R\n# 1)\n(20 + 0.2) / 4.1\n\n\n[1] 4.926829\n\n\nSimple arithmetic in R\n# 2)\n6 * (2 + 1300)\n\n\n[1] 7812\n\n\nQ 2\nThis one is just about setting up a project in RStudio and developing a consistent organization and naming system for project files. I’ve done this extensively in the back end, I promise ;)\nQ 3\nThe task for this one is simply to set up a Quarto document (done) and use an R code block as a calculator for a word problem. I’m going to take some liberty and write a calculator function, instead!\n“It costs $100 for each professor and $25 for each student to register for a conference. Write a function to calculate the total cost for any professor-student combination.”\n\n\nInstantiate regCost() function\nregCost &lt;- function(professors = 0, students = 0, profCost = 100, studCost = 25) {\n  professorTotal &lt;- professors * profCost\n  studentTotal &lt;- students * studCost\n  registrationTotal &lt;- professorTotal + studentTotal\n  return(str_c(\"Total cost for registering \", professors, \" professors and \", students, \" students: $\", registrationTotal))\n}\n\n\nExample: 8 professors and 20 students\n\n\nRun regCost for 8 professors and 20 students\nregCost(professors = 8, students = 20)\n\n\n[1] \"Total cost for registering 8 professors and 20 students: $1300\"\n\n\nExample: 2 professors and 32 students, but prices have increased to $110 for professors and $30 for students.\n\n\nRun regCost for 8 professors (at $110 per) and 32 students (at $30 per)\nregCost(2, 32, 110, 30)\n\n\n[1] \"Total cost for registering 2 professors and 32 students: $1180\"\n\n\n\n\nWeek 3\nWe’re still in the basic section of class, so it’s mostly just more questions about variable assignment and function calls. As these topics are still pretty rudimentary, I’m going to editorialize a bit more and I will mostly just be providing the solutions for the questions until we get into more advanced topics.\n\n\nVariable name debugging\n# score@T1 &lt;- 3.2 will throw error - @ operator in var name\nscore_at_T1 &lt;- 3.2\n# score at &lt;- 3.2 will throw error - spaces in var name\n# 1_score &lt;- 3.3 will throw error - var assignment starts with integer\nScoreAtTime1 &lt;- 3.2\n\n\n\n\nCode\ny &lt;- cos(3)\ny\n\n\n[1] -0.9899925\n\n\nCode\nround(y)\n\n\n[1] -1\n\n\nCode\nround(y, 2)\n\n\n[1] -0.99\n\n\nThese questions covered vectors, strings, and packages\n\n\ninstantiating integer vectors and calculating with vectors\nsales &lt;- c(30, 50, 40)\ncosts &lt;- c(15, 15, 100)\nprofits &lt;- sales - costs\nprofits\n\n\n[1]  15  35 -60\n\n\ninstantiating integer vectors and calculating with vectors\ntotalProfits &lt;- sum(profits)\nif_else(\n  condition = totalProfits &gt; 0,\n  true = message &lt;- \"Total profit: $\",\n  false = message &lt;- \"Total debt: $\"\n)\n\n\n[1] \"Total debt: $\"\n\n\ninstantiating integer vectors and calculating with vectors\nwriteLines(str_c(message, totalProfits))\n\n\nTotal debt: $-10\n\n\n\n\ninstantiating vectors with strings and demonstrating useful functions to summarize and manipulate strings\nflavors &lt;- c(\"Cookies & Cream\", \"Americone Dream (R)\", \"Bob Marley's 1 Love\")\nlength(flavors)\n\n\n[1] 3\n\n\ninstantiating vectors with strings and demonstrating useful functions to summarize and manipulate strings\nnchar(flavors)\n\n\n[1] 15 19 19\n\n\ninstantiating vectors with strings and demonstrating useful functions to summarize and manipulate strings\nstr_to_upper(flavors)\n\n\n[1] \"COOKIES & CREAM\"     \"AMERICONE DREAM (R)\" \"BOB MARLEY'S 1 LOVE\"\n\n\n\n\nBrowsing vignettes to access documentation from libraries\nbrowseVignettes(\"tidyverse\")\n\n\nstarting httpd help server ... done\n\n\n\n\nWeek 4\nThis question tasked us with tidying the following table: \n\n\nTidying the data\n# Establish data vectors\nseason &lt;- c(1, 2, 3, 4, 5.1, 5.2)\nepisodes &lt;- c(7, 13, 13, 13, 8, 8)\nfirstAired &lt;- mdy(c(\"01-20-2008\", \"03-08-2009\", \"03-21-2010\", \"07-17-2011\", \"07-15-2012\", \"08-11-2013\"))\nlastAired &lt;- mdy(c(\"03-09-2008\", \"05-31-2009\", \"06-13-2010\", \"08-09-2011\", \"10-02-2012\", \"10-02-2013\"))\n\n# Construct the tibble\nbreaking_bad &lt;- tibble(\n  Season = season,\n  Episodes = episodes,\n  First_Aired = firstAired,\n  Last_Aired = lastAired,\n  Network = \"AMC\"\n) |&gt;\n  print()\n\n\n# A tibble: 6 × 5\n  Season Episodes First_Aired Last_Aired Network\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;date&gt;      &lt;date&gt;     &lt;chr&gt;  \n1    1          7 2008-01-20  2008-03-09 AMC    \n2    2         13 2009-03-08  2009-05-31 AMC    \n3    3         13 2010-03-21  2010-06-13 AMC    \n4    4         13 2011-07-17  2011-08-09 AMC    \n5    5.1        8 2012-07-15  2012-10-02 AMC    \n6    5.2        8 2013-08-11  2013-10-02 AMC    \n\n\n\n\nWeek 5\n\n\nWeek 6\n\n\nWeek 11\n\n\nWeek 12\n\n\nWeek 13\n\n\nWeek 14"
  },
  {
    "objectID": "posts/UFO_Prj/UFOs.html",
    "href": "posts/UFO_Prj/UFOs.html",
    "title": "UFOs - CORGIS.edu",
    "section": "",
    "text": "#Load resources\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nUFOData &lt;- read.csv(\"Data/ufo_sightings.csv\")\nhead(UFOData)\n\n  Location.City Location.State Location.Country Data.Shape\n1  anchor point             AK               US       disk\n2     anchorage             AK               US   changing\n3     anchorage             AK               US   changing\n4     anchorage             AK               US      cigar\n5     anchorage             AK               US     circle\n6     anchorage             AK               US     circle\n  Data.Encounter.duration\n1                     300\n2                   21600\n3                     600\n4                      15\n5                     300\n6                       4\n                                                                                           Data.Description.excerpt\n1          Large UFO over Mt. ILIAMNA Alaska.  ((NUFORC Note:  Possible contrail behind a high-altitude jet??  PD))\n2             We could observe red lights dancing across the underside red lights were very bright and very active.\n3                                INTENSE AMBER-ORANGE HONEYCOMB SHAPED DUAL HORIZONTAL LIGHT;&#44 SILENT DECENT....\n4           I explained away the first time I thought I seen this object but twice weeks apart...I&#39m certain now\n5                                                              Orange circles &quot;climbing&quot; then fading away\n6 Large&#44 bright&#44 blue/white circular object appeared to do  extremely high speed &quot;fly-by&quot; of Earth.\n  Location.Coordinates.Latitude. Location.Coordinates.Longitude.\n1                       59.77667                       -151.8314\n2                       61.21806                       -149.9003\n3                       61.21806                       -149.9003\n4                       61.21806                       -149.9003\n5                       61.21806                       -149.9003\n6                       61.21806                       -149.9003\n  Dates.Sighted.Year Dates.Sighted.Month Date.Sighted.Day Dates.Sighted.Hour\n1               2005                   5               24                 18\n2               2000                  12               31                 21\n3               2006                  10               23                 21\n4               2014                   3               29                 20\n5               2011                  10               21                 21\n6               1972                   8               30                  1\n  Dates.Sighted.Minute Dates.Documented.Year Dates.Documented.Month\n1                   30                  2005                      5\n2                    0                  2001                      2\n3                    3                  2006                     12\n4                   45                  2014                      4\n5                    0                  2011                     10\n6                   30                  2004                      1\n  Dates.Documented.Day\n1                   28\n2                   18\n3                    7\n4                    4\n5                   25\n6                   17\n\n\n\n# Sightings by state\n\nSightings &lt;- UFOData |&gt;\n  filter (Location.Country == \"US\") |&gt;\n  select(c(\n    Country = Location.Country,\n    State = Location.State,\n    City = Location.City,\n    ufoShape = Data.Shape,\n    dateYear = Dates.Sighted.Year,\n    dateMonth = Dates.Sighted.Month,\n    dateDay = Date.Sighted.Day,\n    timeHour = Dates.Sighted.Hour,\n    timeMinute = Dates.Sighted.Minute,\n    dateDocumentedYear = Dates.Documented.Year,\n    dateDocumentedMonth = Dates.Documented.Month,\n    dateDocumentedDay = Dates.Documented.Day\n  ))\nhead(Sightings)\n\n  Country State         City ufoShape dateYear dateMonth dateDay timeHour\n1      US    AK anchor point     disk     2005         5      24       18\n2      US    AK    anchorage changing     2000        12      31       21\n3      US    AK    anchorage changing     2006        10      23       21\n4      US    AK    anchorage    cigar     2014         3      29       20\n5      US    AK    anchorage   circle     2011        10      21       21\n6      US    AK    anchorage   circle     1972         8      30        1\n  timeMinute dateDocumentedYear dateDocumentedMonth dateDocumentedDay\n1         30               2005                   5                28\n2          0               2001                   2                18\n3          3               2006                  12                 7\n4         45               2014                   4                 4\n5          0               2011                  10                25\n6         30               2004                   1                17\n\n\n\nSightingsCount &lt;- Sightings |&gt; group_by(State) |&gt; count(dateDecade = round(dateYear, -1), sort=TRUE)\nSightingsCount\n\n# A tibble: 359 × 3\n# Groups:   State [51]\n   State dateDecade     n\n   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;\n 1 CA          2010  4600\n 2 CA          2000  3028\n 3 FL          2010  2334\n 4 WA          2010  1882\n 5 TX          2010  1791\n 6 WA          2000  1421\n 7 PA          2010  1379\n 8 NY          2010  1323\n 9 IL          2010  1322\n10 OH          2010  1241\n# ℹ 349 more rows\n\n\n\n# Basic col plot to show count of sightings per state\nstatesPlot &lt;- ggplot(\n  SightingsCount, \n  aes(x = n, y = reorder(State, n), fill = dateDecade)) +\n  geom_col(width = 0.7) +\n  labs(\n    title = \"UFO Sightings by State\",\n    x = \"Number of Sightings\",\n    y = \"State\",\n    fill = \"Year\",\n    caption = \"data from CORGIS.edu\"\n  )\nstatesPlot\n\n\n\n\n\n\n\n\n\nshapesPlot &lt;- Sightings |&gt; ggplot(aes(y = ufoShape)) +\n  geom_bar()\nshapesPlot"
  },
  {
    "objectID": "posts/VideoGames_Prj/VideoGames.html",
    "href": "posts/VideoGames_Prj/VideoGames.html",
    "title": "Video Games - CORGIS.edu",
    "section": "",
    "text": "# Load resources\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nVGamesData &lt;- read.csv(\"Data/video_games.csv\")\nhead(VGamesData)\n\n                       Title Features.Handheld. Features.Max.Players\n1          Super Mario 64 DS               True                    1\n2     Lumines: Puzzle Fusion               True                    1\n3         WarioWare Touched!               True                    2\n4   Hot Shots Golf: Open Tee               True                    1\n5               Spider-Man 2               True                    1\n6 The Urbz: Sims in the City               True                    1\n  Features.Multiplatform. Features.Online.                Metadata.Genres\n1                    True             True                         Action\n2                    True             True                       Strategy\n3                    True             True Action,Racing / Driving,Sports\n4                    True             True                         Sports\n5                    True             True                         Action\n6                    True             True                     Simulation\n  Metadata.Licensed. Metadata.Publishers Metadata.Sequel. Metrics.Review.Score\n1               True            Nintendo             True                   85\n2               True             Ubisoft             True                   89\n3               True            Nintendo             True                   81\n4               True                Sony             True                   81\n5               True          Activision             True                   61\n6               True                  EA             True                   67\n  Metrics.Sales Metrics.Used.Price Release.Console Release.Rating\n1          4.69              24.95     Nintendo DS              E\n2          0.56              14.95        Sony PSP              E\n3          0.54              22.95     Nintendo DS              E\n4          0.49              12.95        Sony PSP              E\n5          0.45              14.95     Nintendo DS              E\n6          0.41              12.95     Nintendo DS              M\n  Release.Re.release. Release.Year Length.All.PlayStyles.Average\n1                True         2004                     22.716667\n2                True         2004                     10.100000\n3                True         2004                      4.566667\n4                True         2004                      0.000000\n5                True         2004                     13.250000\n6                True         2004                     21.933333\n  Length.All.PlayStyles.Leisure Length.All.PlayStyles.Median\n1                      31.90000                     24.48333\n2                      11.01667                     10.00000\n3                      11.56667                      2.50000\n4                       0.00000                      0.00000\n5                      48.38333                     10.00000\n6                      25.50000                     20.00000\n  Length.All.PlayStyles.Polled Length.All.PlayStyles.Rushed\n1                           57                    14.300000\n2                            5                     9.516667\n3                           57                     2.266667\n4                            0                     0.000000\n5                           37                     7.066667\n6                            7                    16.733333\n  Length.Completionists.Average Length.Completionists.Leisure\n1                      29.76667                      35.03333\n2                       0.00000                       0.00000\n3                      10.00000                      14.10000\n4                       0.00000                       0.00000\n5                      72.56667                      78.86667\n6                      30.03333                      30.03333\n  Length.Completionists.Median Length.Completionists.Polled\n1                     30.00000                           20\n2                      0.00000                            0\n3                      7.25000                           16\n4                      0.00000                            0\n5                     72.56667                            2\n6                     30.03333                            2\n  Length.Completionists.Rushed Length.Main...Extras.Average\n1                     22.01667                     24.91667\n2                      0.00000                      9.75000\n3                      6.80000                      3.85000\n4                      0.00000                      0.00000\n5                     66.28333                     12.76667\n6                     30.03333                     20.83333\n  Length.Main...Extras.Leisure Length.Main...Extras.Median\n1                    29.966667                   25.000000\n2                     9.866667                    9.750000\n3                     5.666667                    3.333333\n4                     0.000000                    0.000000\n5                    17.316667                   12.500000\n6                    25.200000                   20.000000\n  Length.Main...Extras.Polled Length.Main...Extras.Rushed\n1                          16                   18.333333\n2                           2                    9.616667\n3                          11                    2.783333\n4                           0                    0.000000\n5                          12                   10.483333\n6                           3                   16.450000\n  Length.Main.Story.Average Length.Main.Story.Leisure Length.Main.Story.Median\n1                 14.333333                 18.316667                14.500000\n2                 10.333333                 11.083333                10.000000\n3                  1.916667                  2.933333                 1.833333\n4                  0.000000                  0.000000                 0.000000\n5                  8.350000                 11.083333                 8.000000\n6                 15.500000                 15.750000                15.500000\n  Length.Main.Story.Polled Length.Main.Story.Rushed\n1                       21                 9.700000\n2                        3                 9.583333\n3                       30                 1.433333\n4                        0                 0.000000\n5                       23                 5.333333\n6                        2                15.250000\n\n\n\nGames &lt;- tibble(\n  \n)"
  },
  {
    "objectID": "posts/Data2-U2-Grp_Prj/index.html",
    "href": "posts/Data2-U2-Grp_Prj/index.html",
    "title": "Unit 2 Group Project",
    "section": "",
    "text": "For our project, we looked at IMDB’s top 1000 movies (Chong) and each chose a different relationship to analyse to delve deeper."
  },
  {
    "objectID": "posts/Data2-U2-Grp_Prj/index.html#overview",
    "href": "posts/Data2-U2-Grp_Prj/index.html#overview",
    "title": "Unit 2 Group Project",
    "section": "",
    "text": "For our project, we looked at IMDB’s top 1000 movies (Chong) and each chose a different relationship to analyse to delve deeper."
  },
  {
    "objectID": "posts/Data2-U2-Grp_Prj/index.html#data-wrangling",
    "href": "posts/Data2-U2-Grp_Prj/index.html#data-wrangling",
    "title": "Unit 2 Group Project",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n\nLoading libraries (tidyverse, dplyr, patchwork)\n# Load libraries\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(patchwork)\n\n\n\n\nLoading data files\n## Load files\nimdbClean &lt;- read_csv(\"Data/imdb_clean.csv\") |&gt; \n  rename(gross_m = 'gross(M)')\nimdbRaw &lt;- read_csv(\"Data/imdb_raw.csv\")\n\n\n\n\nSummarize data\n## Summarize by Genres\nimdbGenres &lt;- imdbClean |&gt;\n  dplyr::summarize(\n    genreTotal = sum(gross_m, na.rm = TRUE),\n    gross = (gross_m),\n    films = n_distinct(title, na.rm = TRUE),\n    .by = genre\n  )\n\n## Summarize by Metascores\nimdb_meta_na &lt;- imdbClean|&gt;\n  mutate(metascore = na_if(metascore, 0))\n\ngenre_metascore &lt;- dplyr::summarize(\n  imdbClean,\n  .by = genre,\n  mmetascore = mean(metascore)) |&gt;\n  arrange(desc(mmetascore))\n\n## Sumamrize by Gross Revenue\nimdb_gross_na &lt;- imdbClean |&gt; \n  mutate(\n    gross = if_else(`gross_m` == 0, NA, `gross_m`))\n\ndirector_summary &lt;- imdb_gross_na |&gt; \n  group_by(director) |&gt; \n  dplyr::summarize(\n    avg_rating = mean(rating, na.rm = TRUE),\n    avg_gross = mean(gross, na.rm = TRUE),\n    n_movies = n())\n\n\nTo find our dataset, our group went through Kaggle to find something that caught our eye. We decided we wanted to look at movies, so after debating several datasets, we settled on “IMDB Top 1000 Movies”. The dataset was already cleaned, so we did not have to do much as far as wrangling, but we did change the name of “gross(M)” to avoid complications with parentheses and changed metascore values of zero because these films did not have pages on metacritic, where this score comes from. From there, we used summarize to calculate the total gross revenue, the number of films per genre, and mean metascores by genre.\nEach group member chose a relationship they wanted to consider from there."
  },
  {
    "objectID": "posts/Data2-U2-Grp_Prj/index.html#visualizations",
    "href": "posts/Data2-U2-Grp_Prj/index.html#visualizations",
    "title": "Unit 2 Group Project",
    "section": "Visualizations",
    "text": "Visualizations\n\nExamining the Top 10 Movies by Gross Revenue by Alayna C.\n\n\nAlayna’s code\ndf_unique &lt;- imdbClean %&gt;%\n  distinct(title, gross_m, .keep_all = TRUE)\ntop10_grossing &lt;- df_unique %&gt;%\n  arrange(desc(gross_m)) %&gt;%\n  slice_head(n = 10)\nggplot(top10_grossing, aes(x = reorder(title, gross_m), y = gross_m)) +\n  geom_point(size = 1.5) +\n  labs(title = \"Top 10 Grossing Movies by Box Office Income\",\n       x = \"Movie Title\",\n       y = \"Gross Income (in Millions)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nMy part in the Unit 2 Project was to create a ggplot based on the top 10 grossing movies in terms of box office income (movies ~ gross_m). I tidied my dataset using the distinct() code to ensure the movie titles aligned with their gross income. Next, I used arrange() and slice_head() to separate the top 10 highest-grossing movies from the rest of the dataset. For the visual aid, I made a scatterplot using ggplot2. I mapped the movie titles to the x-axis and the gross income to the y-axis. The results show which movies had the highest box office income. I also used minimal theming and angled my x-axis movie titles\n\n\nExamining Metascore Ratings by Genre by Emry L.\n\n\nEmry’s code\ntop_5_metascore &lt;- \n  imdb_meta_na |&gt;\n  filter(genre %in% c(\"Western\", \"Animation\", \"Film-Noir\", \"War\", \"Sci-Fi\", \"Thriller\", \"Comedy\", \"Crime\", \"Action\", \"Musical\")) |&gt; \n  mutate(\n    genre = factor(genre, c(\"Western\", \"Animation\", \"Film-Noir\", \"War\", \"Sci-Fi\", \"Thriller\", \"Comedy\", \"Crime\", \"Action\", \"Musical\"))\n  )\n\nggplot(top_5_metascore, aes(x = metascore, y = rating, color = genre)) + \n  geom_point(na.rm = TRUE) + geom_abline(intercept = 0, slope = 1/10) +\n  facet_wrap(~genre) +\n  labs(\n    title = \"Metascore by User Rating Across Genres\",\n    x = \"User Rating\", \n    y = \"Metascore (Critic Rating)\"\n  )\n\n\n\n\n\n\n\n\n\nFor my code, I looked at the metascore (a number created by a site called metacritic that looks at critic reviews, taking into consideration said critic’s reputation) against IMDB user ratings by genre. I used the summary of mean metascore by genre to find the average highest five and lowest five ranked genres, and focused on these 10 genres for my visualization so as to not overwhelm the viewer.\nI used factoring to reorder the data so it would come across in order when I faceted the data. I also decided to use geom_abline to add a line through the visualizations with a slope of 1/10 to make it easier to compare the scores since metascore is out of 100 and rating is out of 10 and uses decimals.\nFrom this visualization, I found that critics and the common viewer overall feel relatively similarly about film genres. However, IMDB users ranked Film-Noir, War, and Animation higher than critics. Critics rated Action, Sci-Fi, and Crime higher than users.\n\n\nExamining Top Directors by Gross Revenue by Sev T.\n\n\nSev’s code\ntop_directors &lt;- director_summary |&gt; \n  arrange(desc(avg_rating)) |&gt; \n  filter(row_number() &lt;= 15)\ntop_directors |&gt; \n  ggplot(aes(x = avg_rating, y = avg_gross)) +\n  geom_point() +\n  geom_text(aes(label = director), vjust = -0.5, size = 2.8) + \n  labs(\n    title = \"Top 15 Directors by Average Rating\",\n    x = \"Average IMDb Rating\",\n    y = \"Average Gross (in millions)\"\n  )\n\n\n\n\n\n\n\n\n\nThe purpose of my code was to look at each of the top 15 directors that made the most gross money. Some of the data had missing data so I replaced the 0 with NA so it would not be included in the calculations. Then I grouped the data to director to filter it. Then, I found each director’s average imdb rating because I wanted to get the top 15 directors by rating. I also averaged their gross earnings & movies because some of the directors made more than one movie and this would be a fair way to see how much money they make on average. After I did that, I made it select the top 15 directors with the highest imdb rating using the filter command. Then I plotted their average using ggplot geompoint. The x axis was the average imdb rating of the director and the y axis was the average gross these actors made which was in millions.\n\n\nExamining Gross Revenue by Genre by Felix G.\n\n\nFelix’s code\nimdbGenres1 &lt;- imdbGenres |&gt;\n  mutate(genre = fct_reorder(genre, films, .desc = TRUE)) |&gt;\n  ggplot(aes(x = genre, y = gross)) + geom_boxplot() +\n  labs(\n    title = \"IMDB's top 1000 movies: Gross revenue per genre\",\n    x = \"Film genre (in order of total films)\",\n    y = \"Gross revenue in millions ($)\"\n  ) +\n  stat_summary(\n    fun = \"mean\",\n    geom = \"point\",\n    color = \"blue\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\nimdbGenres2 &lt;- imdbGenres |&gt;\n  mutate(genre = fct_reorder(genre, genreTotal, .desc = TRUE)) |&gt;\n  ggplot(aes(x = genre, y = gross)) + geom_boxplot() +\n  labs(\n    x = \"Film genre (in order of total gross revenue)\",\n    y = \"Gross revenue in millions ($)\"\n  ) +\n  stat_summary(\n    fun = \"mean\",\n    geom = \"point\",\n    color = \"blue\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\nimdbGenres1 / imdbGenres2\n\n\n\n\n\n\n\n\n\nI wanted to focus on gross revenue for the genres to see whether genre is a good predictor of gross revenue. I chose a boxplot for this, as it shows the interquartile range and clearly shows outliers.\nI then added a stat_summary to show the mean. As we can see, the mean is higher the the median (50th percentile) in almost every genre, which suggests that the distribution is skewed towards higher revenue. On the surface we can see that the genres Adventure, Action, Sci-Fi, Animation, and Fantasy show significantly higher revenue than other genres.\nFinally, I used Patchwork to display both versions of the graph: ordered by total number of films, and ordered by total gross revenue."
  },
  {
    "objectID": "posts/Data2-U2-Grp_Prj/index.html#future-directions",
    "href": "posts/Data2-U2-Grp_Prj/index.html#future-directions",
    "title": "Unit 2 Group Project",
    "section": "Future Directions",
    "text": "Future Directions\nWe discovered multiple shortcomings with this dataset.\nFirst, there were many films with a metacritic score of 0, which we interpreted as missing data. To fix this, we converted those entries to NA to remove them for the metascore analysis.\nSecond, the top 15 directors showed a significant overlapping grouping around the origin point of the graph, suggesting less variance between directors with lower scores. To alleviate this, we decided to remove those data point from the graph to highlight the top 7 directors with greater variance between scores.\nFinally, many of the films in this list have multiple genres. Therefore, the gross revenue of a single film could be added to multiple genres. For example, Star Wars: The Force Awakens is Action, Adventure, and Sci-FI, meaning that its $936.66 million is added to all three genres total gross figure. All of the top 10 movies by gross revenue have 2 or more genres. The resulting graph suggests that Adventure, Action, Sci-Fi, Animation, and Fantasy produce higher gross revenue, but it is likely that many blockbuster films overlap in these common genres.\nTo alleviate this, we recommend that future analysis should include Principal Component Analysis to discover factor loadings associated with genre."
  },
  {
    "objectID": "posts/Data2-U2-Grp_Prj/index.html#resources",
    "href": "posts/Data2-U2-Grp_Prj/index.html#resources",
    "title": "Unit 2 Group Project",
    "section": "Resources",
    "text": "Resources\nChong, A. (updated 2023). IMDB Top 1000 Movies [Data set]. Kaggle. https://www.kaggle.com/datasets/arthurchongg/imdb-top-1000-movies"
  }
]